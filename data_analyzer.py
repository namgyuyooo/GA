"""
ë°ì´í„° ë¶„ì„ ë° ì²˜ë¦¬ ë¡œì§
UTM ì„±ê³¼ ë¶„ì„, íŠ¸ë Œë“œ ë¹„êµ, ì´ìƒì¹˜ íƒì§€
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta


def analyze_utm_performance(utm_data):
    """UTM ìº í˜ì¸ ì„±ê³¼ ë¶„ì„"""
    
    # 1. ìº í˜ì¸ë³„ ì„±ê³¼ ìš”ì•½
    campaign_summary = utm_data.groupby(['Campaign', 'Source', 'Medium']).agg({
        'Users': 'sum',
        'Sessions': 'sum', 
        'Page_Views': 'sum',
        'Conversions': 'sum',
        'Engagement_Rate': 'mean',
        'Avg_Session_Duration': 'mean'
    }).reset_index()
    
    # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
    campaign_summary['Conversion_Rate'] = (
        campaign_summary['Conversions'] / campaign_summary['Sessions'] * 100
    ).round(2)
    
    campaign_summary['Pages_Per_Session'] = (
        campaign_summary['Page_Views'] / campaign_summary['Sessions']
    ).round(2)
    
    # ì„¸ì…˜ ê¸°ì¤€ ì •ë ¬
    campaign_summary = campaign_summary.sort_values('Sessions', ascending=False)
    
    return campaign_summary


def analyze_channel_performance(utm_data):
    """ì±„ë„ë³„ ì„±ê³¼ ë¶„ì„"""
    
    channel_summary = utm_data.groupby('Channel_Group').agg({
        'Users': 'sum',
        'Sessions': 'sum',
        'Conversions': 'sum',
        'Engagement_Rate': 'mean'
    }).reset_index()
    
    # ì±„ë„ë³„ ì ìœ ìœ¨ ê³„ì‚°
    total_sessions = channel_summary['Sessions'].sum()
    channel_summary['Session_Share'] = (
        channel_summary['Sessions'] / total_sessions * 100
    ).round(2)
    
    channel_summary['Conversion_Rate'] = (
        channel_summary['Conversions'] / channel_summary['Sessions'] * 100
    ).round(2)
    
    return channel_summary.sort_values('Sessions', ascending=False)


def analyze_landing_page_performance(landing_data):
    """ëœë”© í˜ì´ì§€ ì„±ê³¼ ë¶„ì„"""
    
    page_summary = landing_data.groupby('Landing_Page').agg({
        'Users': 'sum',
        'Sessions': 'sum',
        'Conversions': 'sum',
        'Bounce_Rate': 'mean'
    }).reset_index()
    
    page_summary['Conversion_Rate'] = (
        page_summary['Conversions'] / page_summary['Sessions'] * 100
    ).round(2)
    
    # ì„±ê³¼ ê¸°ì¤€ ì •ë ¬ (ì „í™˜ìœ¨ ë†’ì€ ìˆœ)
    page_summary = page_summary.sort_values('Conversion_Rate', ascending=False)
    
    return page_summary


def analyze_search_performance(gsc_data):
    """ê²€ìƒ‰ ì„±ê³¼ ë¶„ì„"""
    
    # 1. ìƒìœ„ í‚¤ì›Œë“œ ë¶„ì„
    top_keywords = gsc_data.head(20).copy()
    
    # 2. CTR ê¸°ì¤€ ë¶„ì„ (CTR 5% ì´ìƒ ê³ ì„±ê³¼ í‚¤ì›Œë“œ)
    high_ctr_keywords = gsc_data[gsc_data['CTR'] >= 0.05].sort_values('Clicks', ascending=False)
    
    # 3. ë…¸ì¶œ ëŒ€ë¹„ í´ë¦­ ë¶€ì¡± í‚¤ì›Œë“œ (ë…¸ì¶œ ë§ì§€ë§Œ CTR ë‚®ìŒ)
    low_ctr_high_impressions = gsc_data[
        (gsc_data['Impressions'] >= 1000) & (gsc_data['CTR'] <= 0.02)
    ].sort_values('Impressions', ascending=False)
    
    # 4. ìˆœìœ„ ê°œì„  ê°€ëŠ¥ í‚¤ì›Œë“œ (4~10ìœ„)
    rank_improvement_opportunity = gsc_data[
        (gsc_data['Position'] >= 4) & (gsc_data['Position'] <= 10)
    ].sort_values('Impressions', ascending=False)
    
    return {
        'top_keywords': top_keywords,
        'high_ctr_keywords': high_ctr_keywords,
        'low_ctr_opportunities': low_ctr_high_impressions,
        'rank_opportunities': rank_improvement_opportunity
    }


def detect_performance_anomalies(current_data, historical_data=None):
    """ì„±ê³¼ ì´ìƒì¹˜ íƒì§€ (ê¸‰ì¦/ê¸‰ê°)"""
    
    anomalies = []
    
    if historical_data is not None:
        # ì´ì „ ì£¼ ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°
        for metric in ['Sessions', 'Users', 'Conversions']:
            current_total = current_data[metric].sum()
            historical_total = historical_data[metric].sum()
            
            if historical_total > 0:
                change_pct = ((current_total - historical_total) / historical_total * 100)
                
                if abs(change_pct) >= 30:  # 30% ì´ìƒ ë³€í™”
                    anomalies.append({
                        'metric': metric,
                        'change_pct': round(change_pct, 2),
                        'current_value': current_total,
                        'previous_value': historical_total,
                        'alert_type': 'ê¸‰ì¦' if change_pct > 0 else 'ê¸‰ê°'
                    })
    
    # ìº í˜ì¸ë³„ ì´ìƒì¹˜ íƒì§€ (Z-score ê¸°ë°˜)
    sessions_mean = current_data['Sessions'].mean()
    sessions_std = current_data['Sessions'].std()
    
    if sessions_std > 0:
        current_data['Sessions_ZScore'] = (
            (current_data['Sessions'] - sessions_mean) / sessions_std
        )
        
        # Z-score 2 ì´ìƒì¸ ìº í˜ì¸ (í†µê³„ì  ì´ìƒì¹˜)
        outlier_campaigns = current_data[
            abs(current_data['Sessions_ZScore']) >= 2
        ][['Campaign', 'Source', 'Medium', 'Sessions', 'Sessions_ZScore']]
        
        if len(outlier_campaigns) > 0:
            anomalies.append({
                'type': 'campaign_outliers',
                'data': outlier_campaigns
            })
    
    return anomalies


def generate_insights(utm_summary, channel_summary, search_analysis):
    """ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    
    insights = []
    
    # 1. ìµœê³  ì„±ê³¼ ìº í˜ì¸
    top_campaign = utm_summary.iloc[0]
    insights.append(
        f"ğŸ† ìµœê³  ì„±ê³¼ ìº í˜ì¸: '{top_campaign['Campaign']}' "
        f"({top_campaign['Sessions']:,}ì„¸ì…˜, {top_campaign['Conversions']}ì „í™˜)"
    )
    
    # 2. ì „í™˜ìœ¨ ê¸°ì¤€ ìµœê³  ìº í˜ì¸
    if len(utm_summary) > 0:
        best_conversion_campaign = utm_summary.loc[utm_summary['Conversion_Rate'].idxmax()]
        insights.append(
            f"ğŸ’° ìµœê³  ì „í™˜ìœ¨ ìº í˜ì¸: '{best_conversion_campaign['Campaign']}' "
            f"({best_conversion_campaign['Conversion_Rate']}%)"
        )
    
    # 3. ì£¼ìš” íŠ¸ë˜í”½ ì±„ë„
    top_channel = channel_summary.iloc[0]
    insights.append(
        f"ğŸ“ˆ ì£¼ìš” íŠ¸ë˜í”½ ì±„ë„: {top_channel['Channel_Group']} "
        f"({top_channel['Session_Share']}% ì ìœ ìœ¨)"
    )
    
    # 4. ê²€ìƒ‰ ì„±ê³¼ ì¸ì‚¬ì´íŠ¸
    top_keyword = search_analysis['top_keywords'].iloc[0]
    insights.append(
        f"ğŸ” ìµœê³  ê²€ìƒ‰ í‚¤ì›Œë“œ: '{top_keyword['Query']}' "
        f"({top_keyword['Clicks']}í´ë¦­, {top_keyword['CTR']*100:.1f}% CTR)"
    )
    
    # 5. ê°œì„  ê¸°íšŒ
    if len(search_analysis['low_ctr_opportunities']) > 0:
        low_ctr_keyword = search_analysis['low_ctr_opportunities'].iloc[0]
        insights.append(
            f"âš ï¸ CTR ê°œì„  ê¸°íšŒ: '{low_ctr_keyword['Query']}' "
            f"({low_ctr_keyword['Impressions']:,}ë…¸ì¶œ, {low_ctr_keyword['CTR']*100:.1f}% CTR)"
        )
    
    return insights


def create_performance_summary(utm_data, gsc_data):
    """ì „ì²´ ì„±ê³¼ ìš”ì•½ ìƒì„±"""
    
    # ê¸°ë³¸ í†µê³„
    total_sessions = utm_data['Sessions'].sum()
    total_users = utm_data['Users'].sum()
    total_conversions = utm_data['Conversions'].sum()
    total_clicks = gsc_data['Clicks'].sum()
    total_impressions = gsc_data['Impressions'].sum()
    
    # í‰ê·  ì§€í‘œ
    avg_engagement_rate = utm_data['Engagement_Rate'].mean()
    avg_ctr = gsc_data['CTR'].mean()
    avg_position = gsc_data['Position'].mean()
    
    # ìº í˜ì¸/í‚¤ì›Œë“œ ìˆ˜
    unique_campaigns = utm_data['Campaign'].nunique()
    unique_keywords = len(gsc_data)
    
    summary = {
        'period': 'ì§€ë‚œì£¼',
        'utm_performance': {
            'total_sessions': total_sessions,
            'total_users': total_users,
            'total_conversions': total_conversions,
            'avg_engagement_rate': round(avg_engagement_rate, 4),
            'unique_campaigns': unique_campaigns
        },
        'search_performance': {
            'total_clicks': total_clicks,
            'total_impressions': total_impressions,
            'avg_ctr': round(avg_ctr, 4),
            'avg_position': round(avg_position, 1),
            'unique_keywords': unique_keywords
        }
    }
    
    return summary


if __name__ == "__main__":
    print("ë°ì´í„° ë¶„ì„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸...")
    
    # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°
    test_utm_data = pd.DataFrame({
        'Campaign': ['summer_sale', 'brand_awareness', 'summer_sale'],
        'Source': ['google', 'facebook', 'naver'],
        'Medium': ['cpc', 'social', 'cpc'],
        'Channel_Group': ['Paid Search', 'Social', 'Paid Search'],
        'Users': [1000, 500, 300],
        'Sessions': [1200, 600, 350],
        'Page_Views': [2400, 900, 700],
        'Conversions': [50, 15, 20],
        'Engagement_Rate': [0.75, 0.65, 0.80],
        'Avg_Session_Duration': [120, 90, 110]
    })
    
    utm_summary = analyze_utm_performance(test_utm_data)
    print("UTM ë¶„ì„ ì™„ë£Œ:", len(utm_summary), "í–‰")